# kafka Channel + HDFS sink(without sources)
a1.channels = c2 c3 c4 c5
a1.sinks = s2 s3 s4 s5

# cdh 集群 kafka
a1.channels.c2.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c2.kafka.bootstrap.servers = cdh04:9092,cdh05:9092,cdh07:9092
a1.channels.c2.parseAsFlumeEvent = false
a1.channels.c2.kafka.topic = matrix-device-multi-static
a1.channels.c2.kafka.consumer.group.id = matrix-input-flume-group

# cdh 集群 kafka
a1.channels.c3.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c3.kafka.bootstrap.servers = cdh04:9092,cdh05:9092,cdh07:9092
a1.channels.c3.parseAsFlumeEvent = false
a1.channels.c3.kafka.topic = matrix-archive-multi-static
a1.channels.c3.kafka.consumer.group.id = matrix-input-flume-group

# cdh 集群 kafka
a1.channels.c4.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c4.kafka.bootstrap.servers = cdh04:9092,cdh05:9092,cdh07:9092
a1.channels.c4.parseAsFlumeEvent = false
a1.channels.c4.kafka.topic = matrix-relationship-multi-static
a1.channels.c4.kafka.consumer.group.id = matrix-input-flume-group

# cdh 集群 kafka
a1.channels.c5.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c5.kafka.bootstrap.servers = cdh04:9092,cdh05:9092,cdh07:9092
a1.channels.c5.parseAsFlumeEvent = false
a1.channels.c5.kafka.topic = matrix-archive-label-static
a1.channels.c5.kafka.consumer.group.id = matrix-input-flume-group

# 定义 HDFS sink
a1.sinks.s2.channel = c2
a1.sinks.s3.channel = c3
a1.sinks.s4.channel = c4
a1.sinks.s5.channel = c5

a1.sinks.s2.type = hdfs
a1.sinks.s2.hdfs.path = /user/flume/device_multi_matrix/%Y%m%d
a1.sinks.s2.hdfs.useLocalTimeStamp = true
a1.sinks.s2.hdfs.filePrefix = device
a1.sinks.s2.hdfs.fileType = DataStream
a1.sinks.s2.hdfs.writeFormat = Text
# 不按照条数生成文件
a1.sinks.s2.hdfs.rollCount = 0
# HDFS 上的文件达到128M 生成一个文件
a1.sinks.s2.hdfs.rollSize = 134217728
# hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；如果设置成0，则表示不根据时间来滚动文件；
a1.sinks.s2.hdfs.rollInterval = 3600

a1.sinks.s3.type = hdfs
a1.sinks.s3.hdfs.path = /user/flume/archive_multi_matrix/%Y%m%d
a1.sinks.s3.hdfs.useLocalTimeStamp = true
a1.sinks.s3.hdfs.filePrefix = archive
a1.sinks.s3.hdfs.fileType = DataStream
a1.sinks.s3.hdfs.writeFormat = Text
# 不按照条数生成文件
a1.sinks.s3.hdfs.rollCount = 0
# HDFS 上的文件达到128M 生成一个文件
a1.sinks.s3.hdfs.rollSize = 134217728
# hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；如果设置成0，则表示不根据时间来滚动文件；
a1.sinks.s3.hdfs.rollInterval = 3600

a1.sinks.s4.type = hdfs
a1.sinks.s4.hdfs.path = /user/flume/relationship_multi_matrix/%Y%m%d
a1.sinks.s4.hdfs.useLocalTimeStamp = true
a1.sinks.s4.hdfs.filePrefix = relationship
a1.sinks.s4.hdfs.fileType = DataStream
a1.sinks.s4.hdfs.writeFormat = Text
# 不按照条数生成文件
a1.sinks.s4.hdfs.rollCount = 0
# HDFS 上的文件达到128M 生成一个文件
a1.sinks.s4.hdfs.rollSize = 134217728
# hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；如果设置成0，则表示不根据时间来滚动文件；
a1.sinks.s4.hdfs.rollInterval = 3600

a1.sinks.s5.type = hdfs
a1.sinks.s5.hdfs.path = /user/flume/archive_label_matrix/%Y%m%d
a1.sinks.s5.hdfs.useLocalTimeStamp = true
a1.sinks.s5.hdfs.filePrefix = label
a1.sinks.s5.hdfs.fileType = DataStream
a1.sinks.s5.hdfs.writeFormat = Text
# 不按照条数生成文件
a1.sinks.s5.hdfs.rollCount = 0
# HDFS 上的文件达到128M 生成一个文件
a1.sinks.s5.hdfs.rollSize = 134217728
# hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；如果设置成0，则表示不根据时间来滚动文件；
a1.sinks.s5.hdfs.rollInterval = 3600