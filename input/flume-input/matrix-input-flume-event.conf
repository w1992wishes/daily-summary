# kafka Channel + HDFS sink(without sources)
a1.channels = c1 c2
a1.sinks = s1 s2

# cdh 集群 kafka
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c1.kafka.bootstrap.servers = ds1:9092,ds1:9092,ds1:9092
a1.channels.c1.parseAsFlumeEvent = false
a1.channels.c1.kafka.topic = matrix-event-multi-dynamic
a1.channels.c1.kafka.consumer.group.id = matrix-input-flume-event-group

# cdh 集群 kafka
a1.channels.c2.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c2.kafka.bootstrap.servers = ds1:9092,ds1:9092,ds1:9092
a1.channels.c2.parseAsFlumeEvent = false
a1.channels.c2.kafka.topic = matrix-event-scenic-area
a1.channels.c2.kafka.consumer.group.id = matrix-input-flume-event-group

# 定义 HDFS sink
a1.sinks.s1.channel = c1
a1.sinks.s2.channel = c2

a1.sinks.s1.type = hdfs
a1.sinks.s1.hdfs.path = /user/flume/event_multi_matrix/%Y%m%d
a1.sinks.s1.hdfs.useLocalTimeStamp = true
a1.sinks.s1.hdfs.filePrefix = event
a1.sinks.s1.hdfs.fileType = DataStream
a1.sinks.s1.hdfs.writeFormat = Text
# 不按照条数生成文件
a1.sinks.s1.hdfs.rollCount = 0
# HDFS 上的文件达到128M 生成一个文件
a1.sinks.s1.hdfs.rollSize = 134217728
# hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；如果设置成0，则表示不根据时间来滚动文件；
a1.sinks.s1.hdfs.rollInterval = 3600

a1.sinks.s2.type = hdfs
a1.sinks.s2.hdfs.path = /user/flume/matrix/event_scenic_area_booking/%Y%m%d
a1.sinks.s2.hdfs.useLocalTimeStamp = true
a1.sinks.s2.hdfs.filePrefix = event
a1.sinks.s2.hdfs.fileType = DataStream
a1.sinks.s2.hdfs.writeFormat = Text
# 不按照条数生成文件
a1.sinks.s2.hdfs.rollCount = 0
# HDFS 上的文件达到128M 生成一个文件
a1.sinks.s2.hdfs.rollSize = 134217728
# hdfs sink间隔多长将临时文件滚动成最终目标文件，单位：秒；如果设置成0，则表示不根据时间来滚动文件；
a1.sinks.s2.hdfs.rollInterval = 3600